{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 15 classes: ['Blazer', 'Celana_Panjang', 'Celana_Pendek', 'Gaun', 'Hoodie', 'Jaket', 'Jaket_Denim', 'Jaket_Olahraga', 'Jeans', 'Kaos', 'Kemeja', 'Mantel', 'Polo', 'Rok', 'Sweter']\n",
      "Epoch 1: training loss = 2.4088, validation loss = 2.1808\n",
      "Epoch 2: training loss = 1.9752, validation loss = 1.9010\n",
      "Epoch 3: training loss = 1.6598, validation loss = 1.7518\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39  2  5  1  1  2  4  5  1  2  3 16  5 14  9]\n",
      " [ 5 66  4  3  0  3  1  2  4  0  0  5  1  2  3]\n",
      " [ 3  2 55  1  0  5  0  0  0  0  1  1  1  9  4]\n",
      " [ 4  5  5 19  5  5  0  4  0  0  5 12  5 20 10]\n",
      " [ 1  2  0  1 35 14  2  5  0  1  2  6  1  4  8]\n",
      " [ 3  0  5  2  6 42  6  4  0  0  5  6  2  4  7]\n",
      " [ 7  2  3  0  4 12 55  4  0  0  2  2  1  3  4]\n",
      " [ 9  1  4  0  5 18  1 27  1  2  3  6  4  6  5]\n",
      " [ 0 41  5  1  3  3  3  1 42  1  0  3  0  4  0]\n",
      " [ 1  1  1  3  5  6  4  4  0 44  3  0 18  6  8]\n",
      " [ 6  1  4  0  3  9  2  2  0  3 40  7 10 13  8]\n",
      " [13  4  2  1  2  6  6  2  0  1  1 50  1  4  6]\n",
      " [ 6  3  2  0  5  5  0  2  0  8  5  1 43  3  7]\n",
      " [ 5  8  8  6  2  4  4  5  0  1  3  9  5 53  3]\n",
      " [ 7  1  2  1  4  4  3  6  0  6  4  4  6  2 72]]\n",
      "F1 Score: 0.4516\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "\n",
    "# Custom Dataset that reads images from a root directory structured by class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the class folders.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        # List and sort the class directories\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Traverse each class directory and store image paths with their corresponding label\n",
    "        for cls in self.classes:\n",
    "            cls_folder = os.path.join(root_dir, cls)\n",
    "            for fname in os.listdir(cls_folder):\n",
    "                if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    self.samples.append((os.path.join(cls_folder, fname), self.class_to_idx[cls]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.samples[index]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# A simple CNN model with four convolutional blocks\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Assuming input images are resized to 224x224, four max pools reduce spatial dims: 224->56->28->14.\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # (B, 16, 224, 224)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4, 4),                          # (B, 16, 56, 56)\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # (B, 32, 56, 56)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                          # (B, 32, 28, 28)\n",
    "        \n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),# (B, 32, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)                           # (B, 32, 14, 14)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 14 * 14, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # Flatten the feature maps\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "def main():\n",
    "    # Define transforms: following MobileNetV3 preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),  # scales to [0.0, 1.0]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create the dataset from the root folder\n",
    "    dataset = CustomDataset(root_dir='archive/Clothes_Dataset', transform=transform)\n",
    "    num_classes = len(dataset.classes)\n",
    "    print(f\"Found {len(dataset)} images belonging to {num_classes} classes: {dataset.classes}\")\n",
    "    \n",
    "    # Split dataset into training (80%) and validation (20%) sets\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Create DataLoaders for training and validation\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training for 3 epochs with aggregated loss calculation\n",
    "    num_epochs = 3\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        \n",
    "        # Print the aggregated losses in the required format\n",
    "        print(f\"Epoch {epoch+1}: training loss = {avg_train_loss:.4f}, validation loss = {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # ----- Compute and Display the Confusion Matrix on Validation Set -----\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"F1 Score: {f1_score(all_labels, all_preds, average='macro'):.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 15 classes: ['Blazer', 'Celana_Panjang', 'Celana_Pendek', 'Gaun', 'Hoodie', 'Jaket', 'Jaket_Denim', 'Jaket_Olahraga', 'Jeans', 'Kaos', 'Kemeja', 'Mantel', 'Polo', 'Rok', 'Sweter']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /home/strongich/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100%|██████████| 9.83M/9.83M [00:00<00:00, 51.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial F1 score on validation set: 0.0313\n",
      "Epoch 1/3: Training Loss = 1.4874\n",
      "Epoch 2/3: Training Loss = 0.9925\n",
      "Epoch 3/3: Training Loss = 0.8193\n",
      "F1 score on validation set after fine-tuning: 0.6200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "\n",
    "# Custom Dataset for our Clothes_Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory with all class folders.\n",
    "            transform (callable, optional): Transformations to be applied to an image.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        # Get sorted list of class directories\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Traverse each class directory and store image paths with their corresponding label\n",
    "        for cls in self.classes:\n",
    "            cls_folder = os.path.join(root_dir, cls)\n",
    "            for fname in os.listdir(cls_folder):\n",
    "                if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    self.samples.append((os.path.join(cls_folder, fname), self.class_to_idx[cls]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.samples[index]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    # Compute macro F1 score\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return f1\n",
    "\n",
    "def main():\n",
    "    # Define transforms: using MobileNetV3 preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),  # scales pixel values to [0.0, 1.0]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create the dataset from the root folder\n",
    "    dataset = CustomDataset(root_dir='archive/Clothes_Dataset', transform=transform)\n",
    "    num_classes = len(dataset.classes)\n",
    "    print(f\"Found {len(dataset)} images belonging to {num_classes} classes: {dataset.classes}\")\n",
    "    \n",
    "    # Split dataset into training (80%) and validation (20%) sets\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Create DataLoaders for training and validation with batch_size 16\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Device configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load pre-trained MobileNetV3_small model\n",
    "    model = models.mobilenet_v3_small(weights='IMAGENET1K_V1')\n",
    "    # Replace the classifier's final linear layer with one matching our number of classes\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer for fine-tuning\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # ----- Evaluate initial model (without fine-tuning) on validation set -----\n",
    "    initial_f1 = evaluate_model(model, val_loader, device)\n",
    "    print(f\"Initial F1 score on validation set: {initial_f1:.4f}\")\n",
    "    \n",
    "    # ----- Fine-tuning for 3 epochs -----\n",
    "    num_epochs = 3\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Training Loss = {avg_loss:.4f}\")\n",
    "    \n",
    "    # ----- Evaluate the model after fine-tuning -----\n",
    "    final_f1 = evaluate_model(model, val_loader, device)\n",
    "    print(f\"F1 score on validation set after fine-tuning: {final_f1:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
